{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Predicting World Series Champions\n",
    "The procedure has been borrowed in part from the machine learning class examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "pd.set_option('display.max_columns', None)\n",
    "mlb_df = pd.read_csv('resources/mlb_data.csv')\n",
    "# mlb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the League column to be binary instead of string\n",
    "for i, row in mlb_df.iterrows():\n",
    "#     print(i,row['Lg'])\n",
    "    if row['Lg'] == 'AL':\n",
    "        mlb_df.at[i,'Lg'] = 0\n",
    "#         print(f'new value at {i} is {mlb_df.at[i,\"Lg\"]}')\n",
    "    elif row['Lg'] == 'NL':\n",
    "        mlb_df.at[i,'Lg'] = 1\n",
    "#         print(f'new value at {i} is {mlb_df.at[i,\"Lg\"]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# league is now a 1 or 0\n",
    "# mlb_df.head()\n",
    "# mlb_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and testing set\n",
    "Manually split the data by season. Odd years will be used for training, while even years will be used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and Y train for making the model\n",
    "train_df = mlb_df.loc[mlb_df['Year'] % 2 == 1]\n",
    "train_data = train_df.values\n",
    "X_train = train_data[:, 3:22]\n",
    "y_train = train_data[:,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and Y for making the model\n",
    "test_df = mlb_df.loc[mlb_df['Year'] % 2 == 0]\n",
    "test_data = test_df.values\n",
    "X_test = test_data[:, 3:22]\n",
    "y_test = test_data[:,23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the winner column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "# y_train_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = 19\n",
    "number_hidden_nodes = 4\n",
    "model.add(Dense(units=number_hidden_nodes, activation='relu', input_dim=number_inputs))\n",
    "model.add(Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 2\n",
    "model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(\n",
    "    x=X_train_scaled,\n",
    "    y=y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=False,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled)\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "# print(f\"Predicted classes: {prediction_labels}\")\n",
    "# print(f\"Actual Labels: {list(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "predictions_df = pd.DataFrame({'Prediction':prediction_labels, 'Actual':list(y_test)})\n",
    "# predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_df = predictions_df.loc[predictions_df['Actual']]\n",
    "# winners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect predictions to the team and season using iloc and test_df\n",
    "teams = []\n",
    "years = []\n",
    "for i, row in winners_df.iterrows():\n",
    "    team = test_df.iloc[i,2]\n",
    "    year = test_df.iloc[i,1]\n",
    "    teams.append(team)\n",
    "    years.append(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display predictions by team\n",
    "winners_df['Team'] = teams\n",
    "winners_df['Year'] = years\n",
    "# winners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using probabilities \n",
    "probs = model.predict_proba(X_test_scaled)\n",
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe cleanup\n",
    "probs_df = pd.DataFrame.from_records(probs)\n",
    "probs_df[0] = probs_df[0] * 100\n",
    "probs_df[1] = probs_df[1] * 100\n",
    "probs_df.rename(columns={0:'False', 1:'True'}, inplace=True)\n",
    "# probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect predictions to the team and season using iloc and test_df\n",
    "all_teams = []\n",
    "all_years = []\n",
    "for i, row in probs_df.iterrows():\n",
    "    team = test_df.iloc[i,2]\n",
    "    year = test_df.iloc[i,1]\n",
    "    all_teams.append(team)\n",
    "    all_years.append(year)\n",
    "# print(all_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add teams to dataframe\n",
    "probs_df['Year'] = all_years\n",
    "probs_df['Team'] = all_teams\n",
    "probs_df.sort_values(by=['Year','True'],ascending=False)\n",
    "# probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add top three most likely teams for each season to a dictionary\n",
    "seasons = probs_df['Year'].unique()\n",
    "top_three = {}\n",
    "for season in seasons:\n",
    "    df = probs_df.loc[probs_df['Year'] == season]\n",
    "    df = df.sort_values(by='True', ascending=False)\n",
    "    top_three[season] = {'first_prediction':df.iloc[0,3], 'second_prediction': df.iloc[1,3], 'third_prediction': df.iloc[2,3]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put dictionary into dataframe\n",
    "top_three_df = pd.DataFrame(top_three)\n",
    "top_three_df = top_three_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by year\n",
    "top_three_df = top_three_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding year as a column\n",
    "top_three_df.reset_index(inplace=True)\n",
    "top_three_df = top_three_df.rename(columns={'index':'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_three_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in actual winners\n",
    "even_df = top_three_df.merge(winners_df, on='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe cleanup\n",
    "even_df.drop(columns=['Prediction','Actual'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_df.rename(columns={'Team':'actual'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Repeat for odd years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "pd.set_option('display.max_columns', None)\n",
    "mlb_df = pd.read_csv('resources/mlb_data.csv')\n",
    "# mlb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the League column to be binary instead of string\n",
    "for i, row in mlb_df.iterrows():\n",
    "#     print(i,row['Lg'])\n",
    "    if row['Lg'] == 'AL':\n",
    "        mlb_df.at[i,'Lg'] = 0\n",
    "#         print(f'new value at {i} is {mlb_df.at[i,\"Lg\"]}')\n",
    "    elif row['Lg'] == 'NL':\n",
    "        mlb_df.at[i,'Lg'] = 1\n",
    "#         print(f'new value at {i} is {mlb_df.at[i,\"Lg\"]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# league is now a 1 or 0\n",
    "# mlb_df.head()\n",
    "# mlb_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and testing set\n",
    "Manually split the data by season. Even years will be used for training, while odd years will be used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and Y train for making the model\n",
    "train_df = mlb_df.loc[mlb_df['Year'] % 2 == 0]\n",
    "train_data = train_df.values\n",
    "X_train = train_data[:, 3:22]\n",
    "y_train = train_data[:,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and Y for making the model\n",
    "test_df = mlb_df.loc[mlb_df['Year'] % 2 == 1]\n",
    "test_data = test_df.values\n",
    "X_test = test_data[:, 3:22]\n",
    "y_test = test_data[:,23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the winner column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "# y_train_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = 19\n",
    "number_hidden_nodes = 4\n",
    "model.add(Dense(units=number_hidden_nodes, activation='relu', input_dim=number_inputs))\n",
    "model.add(Dense(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 2\n",
    "model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(\n",
    "    x=X_train_scaled,\n",
    "    y=y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=False,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled)\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "# print(f\"Predicted classes: {prediction_labels}\")\n",
    "# print(f\"Actual Labels: {list(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-process and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "predictions_df = pd.DataFrame({'Prediction':prediction_labels, 'Actual':list(y_test)})\n",
    "# predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners_df = predictions_df.loc[predictions_df['Actual']]\n",
    "# winners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect predictions to the team and season using iloc and test_df\n",
    "teams = []\n",
    "years = []\n",
    "for i, row in winners_df.iterrows():\n",
    "    team = test_df.iloc[i,2]\n",
    "    year = test_df.iloc[i,1]\n",
    "    teams.append(team)\n",
    "    years.append(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display predictions by team\n",
    "winners_df['Team'] = teams\n",
    "winners_df['Year'] = years\n",
    "# winners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using probabilities \n",
    "probs = model.predict_proba(X_test_scaled)\n",
    "# probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe cleanup\n",
    "probs_df = pd.DataFrame.from_records(probs)\n",
    "probs_df[0] = probs_df[0] * 100\n",
    "probs_df[1] = probs_df[1] * 100\n",
    "probs_df.rename(columns={0:'False', 1:'True'}, inplace=True)\n",
    "# probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect predictions to the team and season using iloc and test_df\n",
    "all_teams = []\n",
    "all_years = []\n",
    "for i, row in probs_df.iterrows():\n",
    "    team = test_df.iloc[i,2]\n",
    "    year = test_df.iloc[i,1]\n",
    "    all_teams.append(team)\n",
    "    all_years.append(year)\n",
    "# print(all_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add teams to dataframe\n",
    "probs_df['Year'] = all_years\n",
    "probs_df['Team'] = all_teams\n",
    "probs_df.sort_values(by=['Year','True'],ascending=False)\n",
    "# probs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add top three most likely teams for each season to a dictionary\n",
    "seasons = probs_df['Year'].unique()\n",
    "top_three = {}\n",
    "for season in seasons:\n",
    "    df = probs_df.loc[probs_df['Year'] == season]\n",
    "    df = df.sort_values(by='True', ascending=False)\n",
    "    top_three[season] = {'first_prediction':df.iloc[0,3], 'second_prediction': df.iloc[1,3], 'third_prediction': df.iloc[2,3]}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put dictionary into dataframe\n",
    "top_three_df = pd.DataFrame(top_three)\n",
    "top_three_df = top_three_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by year\n",
    "top_three_df = top_three_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding year as a column\n",
    "top_three_df.reset_index(inplace=True)\n",
    "top_three_df = top_three_df.rename(columns={'index':'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_three_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in actual winners\n",
    "odd_df = top_three_df.merge(winners_df, on='Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe cleanup\n",
    "odd_df.drop(columns=['Prediction','Actual'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_df.rename(columns={'Team':'actual'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([even_df, odd_df])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='Year')\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add full names to df\n",
    "teams =  ['ANA','ARI','ATL','BAL','BOS','CHC','CHW','CIN','CLE','COL','DET','FLA','HOU','KCR','LAA','LAD','MIA','MIL','MIN','MON','NYM','NYY','OAK','PHI','PIT','SDP','SEA','SFG','STL','TBD','TBR','TEX','TOR','WSN']\n",
    "full_names = ['Anahiem Angels','Arizona Diamondbacks','Atlanta Braves','Baltimore Orioles','Boston Red Sox','Chicago Cubs','Chicago White Sox','Cincinnati Reds','Cleveland Indians','Colorado Rockies','Detroit Tigers','Florida Marlins','Houston Astros','Kansas City Royals','Los Angeles Angels','Los Angeles Dodgers','Miami Marlins','Milwaukee Brewers','Minnesota Twins','Montreal Expos','New York Mets','New York Yankees','Oakland Athletics','Philadelphia Phillies','Pittsburgh Pirates','San Diego Padres','Seattle Mariners','San Francisco Giants','St. Louis Cardinals','Tampa Bay Devil Rays','Tampa Bay Rays','Texas Rangers','Toronto Blue Jays','Washington Nationals']\n",
    "full_names_df = pd.DataFrame({'abbr':teams,'fn':full_names})\n",
    "# full_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(full_names_df, right_on='abbr', left_on='actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'fn':'actual_fn'},inplace=True)\n",
    "df.drop(columns='abbr',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(full_names_df, right_on='abbr', left_on='first_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'fn':'first_prediction_fn'},inplace=True)\n",
    "df.drop(columns='abbr',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(full_names_df, right_on='abbr', left_on='second_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'fn':'second_prediction_fn'},inplace=True)\n",
    "df.drop(columns='abbr',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(full_names_df, right_on='abbr', left_on='third_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'fn':'third_prediction_fn'},inplace=True)\n",
    "df.drop(columns='abbr',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('nn_predictions.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
